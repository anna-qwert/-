Алгоритмы сортировки 
Донцова Анна УИБО-10-24
 Реализация алгоритмов сортировки и поиска

 Алгоритмы сортировки

 1.Сортировка выбором(Selection Sort)

Определение:
Алгоритм ищет минимальный элемент в неотсортированной части массива и меняет его местами с первым элементом этой части.
 Краткое объяснение работы:
На каждом шаге i (от 0 до n-2) алгоритм:

Находит минимум: Проходит по всем элементам от i+1 до конца массива, чтобы найти индекс минимального элемента.

Пример операторов: for-цикл для перебора, if для сравнения элементов и обновления minIndex.

Меняет местами: После нахождения минимума в неотсортированной части, меняет его местами с элементом на позиции i.

Пример операторов: swap или ручная перестановка с использованием временной переменной.
  Результат:
Исходный массив:
64 25 12 22 11 
Отсортированный массив:
11 12 22 25 64 
Временная сложность:
O(n^2) в худшем, среднем и лучшем случаях.

Почему сложность O(n²):
Вне зависимости от исходных данных, алгоритм всегда выполняет примерно n*(n-1)/2 сравнений. Внешний цикл выполняется n-1 раз. Внутренний цикл на i-том шаге делает n-i-1 операций. Суммарно это квадратичная зависимость. Операций обмена всего O(n).

 2. Сортировка обменом ("пузырьковая") (Bubble Sort)
 Определение:
Каждый проход по массиву меняет местами смежные элементы, если они расположены неправильно.
Краткое объяснение работы:

Сравнение и обмен: Для каждого элемента от начала до n-i-1 алгоритм сравнивает его со следующим. Если текущий элемент больше следующего, они меняются местами.

Пример операторов: Вложенные for-циклы, if для сравнения arr[j] > arr[j+1], операция обмена.

Оптимизация (флаг swapped): Если на каком-то проходе не было ни одного обмена, массив уже отсортирован, и работа прекращается.
  Результат:
Исходный массив: [64, 34, 25, 12, 22, 11, 90]
Отсортированный массив: [11, 12, 22, 25, 34, 64, 90]
Временная сложность:
O(n^2) в худшем и среднем случаях, O(n) в лучшем случае (уже отсортированном).
Почему такая сложность:

Худший случай (массив отсортирован в обратном порядке): Требуется n-1 проходов, на каждом из которых выполняется всё больше сравнений. Суммарно ~n²/2 операций, то есть O(n²).

Лучший случай (массив уже отсортирован): С флагом swapped алгоритм сделает всего один проход за O(n).
3. Сортировка вставками (Insertion Sort)
Определение:
Выбирает элемент и вставляет его на нужное место среди ранее отсортированных элементов.
 Краткое объяснение работы:

Выбор элемента: Начиная со второго элемента (i = 1), алгоритм запоминает его как currentValue.

Сдвиг и вставка: Элементы отсортированной части (слева от i), которые больше currentValue, сдвигаются вправо. Когда найдена позиция, где левый элемент меньше или равен currentValue, он вставляется на это место.

Пример операторов: Внешний for-цикл, внутренний while или for для сдвига, присваивание arr[position] = currentValue.
  Результат:
Исходный массив: [12, 11, 13, 5, 6]
Отсортированный массив: [5, 6, 11, 12, 13]
 Временная сложность:
O(n^2) в худшем и среднем случаях, O(n) в лучшем случае (при почти отсортированном массиве).
Почему такая сложность:

Худший случай (массив отсортирован в обратном порядке): Для вставки каждого нового элемента придётся сдвигать всю уже отсортированную часть. Количество операций ~n²/2, то есть O(n²).

Лучший случай (массив уже отсортирован): Внутренний цикл никогда не выполняется, для каждого элемента делается только одно сравнение. Итоговая сложность O(n).


4. Сортировка слиянием (Merge Sort)
Определение:
Разделяет массив на части, сортируя и объединяя их обратно.
 Краткое объяснение работы:
- Массив разделяется на две примерно равные части.
- Каждая половина сортируется отдельно.
- Затем обе половины объединяются в общий отсортированный массив.
  Результат:
Исходный массив:
38 27 43 3 9 82 10 
Отсортированный массив:
3 9 10 27 38 43 82 
 Временная сложность:
O(n\log{n}) в худшем, среднем и лучшем случаях.
Почему временная сложность O(n\log{n})?
Эта сортировка основана на принципах разделения и объединения: массив делится на небольшие фрагменты, затем фрагментам придаётся нужный порядок, и они объединяются в итоговую сортировку.Каждое разделение происходит приблизительно на две равных части, следовательно, глубина дерева рекурсии составит logn.  На каждом уровне дерева рекурсии приходится объединить примерно n элементов (так как объединение занимает линейное время относительно общего количества элементов).  Итоговая формула тогда выглядит как произведение глубины рекурсии (log⁡n) на объем работы на каждом уровне (n), что дает общую оценку O(nlog⁡n).
5. Сортировка Шелла(Shell Sort)
Определение:
Это улучшенная версия сортировки вставками, использующая шаги (интервал), уменьшаясь с каждым проходом.
 Краткое объяснение работы:
- Использует шаг (gap), позволяющий сравнивать удалённые элементы.
- Постепенно сокращает этот интервал, пока не достигнет обычного поведения сортировки вставками.
  Результат:
Исходный массив: [12, 34, 54, 2, 3]
Отсортированный массив: [2, 3, 12, 34, 54]
Временная сложность:
Средняя сложность около O(n^{1.25}), хотя может доходить до O(n^2).

Почему временная сложность варьируется от O(n^{1.25}) до O(n^2)?
Shell sort улучшает обычную сортировку вставками путем добавления концепции «шагов» (gaps). Идея в том, что на первых этапах расстояние между сравнимыми элементами значительно больше, что ускоряет процесс сортировки больших участков массива.Тем не менее, эффективность сильно зависит от выбора начальных расстояний (гэпов). Чем удачнее выбраны гэпы, тем лучше производительность. Например, некоторые стратегии позволяют добиться средней производительности около O(n1.25), однако при неудачных интервалах возможно ухудшение до O(n2).
 6. Быстрая сортировка (Quick Sort)

 Определение:
Делит массив на две части относительно выбранного опорного элемента и рекурсивно сортирует каждую часть.

Краткое объяснение работы:
- Опорный элемент выбирается произвольно.
- Все элементы слева становятся меньше опорного, справа — больше.
- Рекурсия повторяется для обеих сторон.
  Результат:
Исходный массив: [10, 7, 8, 9, 1, 5]
Отсортированный массив: [1, 5, 7, 8, 9, 10]

Временная сложность:
O(n\log{n}) в среднем, O(n^2) в худшем случае (очень плохо подобранный опорный элемент).
Почему временная сложность варьирует от O(n\log{n}) до O(n2)?
Основан на принципе "разделяй и властвуй": выбирается опорный элемент, и массив делится на две части (меньше и больше опорного). Далее каждая часть сортируется рекурсивно.Средняя производительность соответствует глубине рекурсии log⁡n, поскольку каждый уровень деления приближенно удваивает глубину деревьев. Но эта оценка справедлива лишь в случае удачного выбора опорного элемента (желательно близкого к среднему значению).Худший случай возникает, когда каждый раз выбранный опорный элемент оказывается минимальным/максимальным, что ведет к практически полному прохождению всего массива на каждом этапе, вызывая рост до O(n2)
7. Пирамидальная сортировка (Heap Sort)

Определение:
Преобразует массив в двоичную кучу и извлекает максимальный элемент на каждой итерации.

Краткое объяснение работы:
- Сначала строится куча (`max-heap`).
- Потом каждый элемент, расположенный в вершине кучи, помещается в конце массива.
- Структура кучи обновляется, снова превращаясь в `max-heap`.
  Результат:
Исходный массив: 12 11 13 5 6 7
Отсортированный массив: 5 6 7 11 12 13
Временная сложность:
O(n\log{n})в худшем, среднем и лучшем случаях.

Почему временная сложность O(n\log{n}) ?
Heap Sort преобразует массив в структуру типа "куча" (binary heap), а затем вытягивает максимальный элемент сверху кучи и размещает его в нужном месте массива.Создание кучи — операция порядка O(n), а каждое удаление вершины (с последующей коррекцией структуры) — O(log⁡n).Поскольку процедура удаления вершину должна произойти nn раз, сумма операций сводится к O(nlog⁡n).

 Алгоритмы поиска

1. Последовательный поиск

Определение:
Простой перебор элементов массива для нахождения конкретного значения.

Краткое объяснение работы:
- Последовательно просматривает весь массив.
- Если элемент найден, возвращаем его индекс.
- Иначе возвращаем признак отсутствия (-1).
  Результат:
Индекс элемента 7: 3

 Временная сложность:
O(n), где n— длина массива.
Почему временная сложность O(n)?
Такой поиск подразумевает простой просмотр массива подряд, пока не найдется нужный элемент.  В худшем случае (элемент в самом конце или вообще отсутствует) придется пройти весь массив целиком, следовательно, время работы пропорционально количеству элементов, что означает O(n)


2. Бинарный поиск

 Определение:
Дихотомическое деление области поиска для быстрого нахождения элемента в отсортированном массиве.

Краткое объяснение работы:
- Находит среднюю точку массива.
- Если средняя точка равна цели, прекращает поиск.
- В противном случае сужает диапазон поиска.
  Результат:
Индекс элемента 7: 3

 Временная сложность:
O(\log{n}).
Почему временная сложность O(\log{n}). ?
Бинарный поиск возможен только на отсортированном массиве. Его суть в следующем: берём центральную точку массива и смотрим, куда двигаться дальше (левее или правее), исходя из значения в центре.Благодаря такому подходу на каждом шаге мы отбрасываем половину массива, уменьшив объём исследуемой области в два раза. Число необходимых шагов для достижения одиночной ячейки равно логарифму по основанию 2 от длины массива, отсюда временная сложность O(log⁡n).

3. Интерполяционный поиск

Определение:
Прогрессивный алгоритм поиска, рассчитывающий приблизительное положение элемента на основе диапазона ключей.

Краткое объяснение работы:
- Рассчитывается позиция поиска на основе расстояния между начальным и конечным элементами.
- Происходит проверка текущего индекса, и в зависимости от результата сужается область поиска.
  Результат:
Индекс элемента 85: 8

 Временная сложность:
Обычно O(\log{\log{n}}), но может ухудшаться до O(n) при плохом распределении данных.
Почему временная сложность варьируется от O(log⁡log⁡n) до O(n)?
Интерполяционный поиск похож на бинарный, но он пытается предугадать местоположение искомого элемента на основе распределения значений в массиве.Когда распределение равномерное, точность расчетов возрастает, и скорость приближается к O(log⁡log⁡n).  Однако, если распределение резко неравномерно (например, если значения сконцентрированы в узких пределах), расчет точного положения замедляется, и временная сложность ухудшается до O(n).


4. Фибоначчи-поиск

Определение:
Использование числовой последовательности Фибоначчи для оптимизации процесса поиска в отсортированном массиве.

Краткое объяснение работы:
- Формируются индексы, соответствующие числам Фибоначчи.
- Эти индексы определяют возможные точки для проверки.
- Если элемент не совпадает, поиск продолжается, ограничивая область просмотра.
Результат:
Индекс элемента 85: 8

Временная сложность:
O(\log{n}).
Почему временная сложность O(\log{n})?
Fibonacci search действует подобно бинарному поиску, но вместо простого деления массива на две равные части использует числа Фибоначчи для расчёта точек поиска.Подобно бинарному поиску, с каждым шагом исключается значительная часть массива, и дальнейший поиск ведется на меньшей половине. Время, необходимое для нахождения нужного элемента, растет логарифмически с увеличением размеров массива, что дает оценку O(log⁡n).
